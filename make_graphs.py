# make_graphs
# This file aims to construct the graphs used in the paper from the results
#   generated by main.py


# Internal Imports

# External Imports
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.patches import Patch

# Set library-specific globals & states
matplotlib.rcParams.update({'font.size': 18})

# Globals
LOG_LOC="src/slayer/output/sentiment_words/log/"
GRAPH_LOC="src/slayer/output/sentiment_words/graph/final/"
colors = [
    "red",# red
    "green",# green
    "blue",# blue
    "orange",# orange
    "purple"# purple
]
bar_colors = [# This array contains a bunch of desaturated colors so they're easier on the eyes
    "#d6625c",# red
    "#d69b5c",# orange
    "#7db87a",# green
    "#a27db5",# purple
    "#5c8fd6"# blue
]
collection_names = [
    "sentence_imdb",
    "sentence_emotion",
    "word_imdb",
    "word_emotion"
]
window_sizes = [100, 50, 25, 10]
method_collections = [
    [
        "ann_sentence_imdb",
        "snn_sentence_rate_imdb",
        "snn_sentence_rate_rand_imdb"
    ],
    [
        "ann_sentence_emotion",
        "snn_sentence_rate_emotion",
        "snn_sentence_rate_rand_emotion"
    ],
    [
        "ann_word_imdb",
        "snn_word_rate_imdb",
        "snn_word_rate_rand_imdb",
        "snn_word_imdb_512"
    ],
    [
        "ann_word_emotion",
        "snn_word_rate_emotion",
        "snn_word_rate_rand_emotion",
        "snn_word_emotion_32"
    ]
]


# Graph 01: Plot all 100ms validation loss curves
def training_curves(name, methods, target_col="valid_loss", inference_win=50, normalize=True):
    # Initialize the figure
    fig, axs = plt.subplots(2, 2, figsize=(10,8))
    # Flatten the axs array for easy indexing
    axs = axs.flatten()
    # For each collection of methods, make a graph
    for (i, name, methods) in zip(range(4), collection_names, method_collections):
        # Start by loading in all relevant data
        combined_data = pd.DataFrame()
        for method in methods:
            # Read in the log file's data
            filename = (f"{LOG_LOC}final_{inference_win}ms/{method}.csv" if (method.split("_")[0] == "ann" or method.split("_")[-1].isnumeric()) else f"{LOG_LOC}final_{inference_win}ms/{method}_{inference_win}.csv")
            df = pd.read_csv(filename)
            # Add the relevant data to the combined dataframe, normalizing it if needed
            combined_data[method] = (df[target_col] if not normalize else ((df[target_col] - df[target_col].min()) / (df[target_col].max() - df[target_col].min())))
        # Given the relevant data and appropriate labels, generate a single graph
        index = 0
        for column_name in combined_data.columns:
            # Build the data label
            split_column = column_name.split("_")
            label = (f"{column_name.split('_')[0]}_bin" if column_name.split("_")[-1].isnumeric() else column_name.replace(f"_{split_column[1]}", "").replace(f"_{split_column[-1]}", ""))
            split_label = label.split("_")
            label = (label.upper() if not len(split_label) > 1 else f"{split_label[0].upper()}_{'_'.join(split_label[1:])}")
            # Plot the data
            axs[i].plot(combined_data[column_name], label=label, color=colors[index])
            index += 1
        # Add labels and a legend
        axs[i].set_xlabel("Epoch")
        axs[i].set_ylabel(" ".join([x.capitalize() for x in target_col.split("_")]))
        axs[i].legend(loc="upper right")
    # Adjust the layout
    plt.tight_layout()
    # Save the plot
    #plt.savefig(f"{GRAPH_LOC}{methods[0][4:]}_{target_col}_curves_{inference_win}ms.jpg")
    plt.savefig(f"{GRAPH_LOC}{target_col}_curves_{inference_win}ms.jpg")
    plt.close()
#Generate all graphs
for (name, methods) in zip(collection_names, method_collections):
    training_curves(name, methods)


# Graph 02: Plot test accuracy (as grouped bar graph) for each method on each task
#   on each inference window
def accuracy_graphs(task, measure):
    # Read in all performance information for all inference window sizes
    data = {"imdb":{},"emotion":{}}
    for key in data.keys():
        for size in window_sizes:
            data[key][str(size)] = {}
    for size in window_sizes:
        # Read in the test data
        filename = f"{LOG_LOC}final_{size}ms/test_results.csv"
        df = pd.read_csv(filename)
        # Store all relevant information
        #print(df.iloc[:,:4])
        for index, row in df.iloc[:,:4].iterrows():
            if "imdb" in row["model"]:
                if "ann" in row["model"]:
                    data["imdb"]["ann"] = row
                elif ("rate" in row["model"]) and (not "rate_rand" in row["model"]):
                    data["imdb"][str(size)]["rate"] = row
                elif "rate_rand" in row["model"]:
                    data["imdb"][str(size)]["rate_rand"] = row
                else: # binarized data
                    data["imdb"]["bin"] = row
            else: # "emotion" in row["model"]
                if "ann" in row["model"]:
                    data["emotion"]["ann"] = row
                elif ("rate" in row["model"]) and (not "rate_rand" in row["model"]):
                    data["emotion"][str(size)]["rate"] = row
                elif "rate_rand" in row["model"]:
                    data["emotion"][str(size)]["rate_rand"] = row
                else: # binarized data
                    data["emotion"]["bin"] = row
        #print(data)
    # Consolidate
    # Make graph
    labels = ["ANN", "SNN-rate", "SNN-rate-rand", "SNN-bin"]
    fig, axs = plt.subplots(2, 1, figsize=(10,8))
    axs = axs.flatten()
    # Make the sub-graphs
    bar_width = .24
    ax_index = 0
    bar_index = 1
    for scope in ["sentence", "word"]:
        mod_labels = (labels if scope == "word" else labels[:-1])
        #print(mod_labels)
        for label in mod_labels:
            # Plot all bars
            if label == "ANN" or label == "SNN-bin":
                data_label = ("ann" if label == "ANN" else "bin")
                axs[ax_index].bar(bar_index, data[task][data_label][measure], bar_width/2, label=label, color=bar_colors[-1])
            else:
                data_label = ("rate" if label == "SNN-rate" else "rate_rand")
                i = 0
                for num, size in zip([0-bar_width*3/4, 0-bar_width/4, bar_width/4, bar_width*3/4], window_sizes):
                    axs[ax_index].bar(bar_index + num, data[task][str(size)][data_label][measure], bar_width/2, label=f"{label}-{size}", color=bar_colors[i])
                    i += 1
            # Set the scope to the other value
            bar_index += 1
        # Set axis labels & constraints
        if len(mod_labels) == 3:
            mod_labels.append("")
        mod_labels.insert(0, "")
        mod_labels.append("")
        #axs[ax_index].set_xlabel("Method")
        axs[ax_index].set_ylabel((measure.capitalize() if measure == "accuracy" else measure.upper()))
        axs[ax_index].set_xticks(range(len(mod_labels)))
        axs[ax_index].set_xticklabels(mod_labels)
        y_ticks = [.3, .4, .5, .6, .7, .8, .9]
        axs[ax_index].set_ylim(y_ticks[0], y_ticks[-1])
        axs[ax_index].set_yticks(y_ticks)
        #axs[ax_index].legend()
        # If this is the top graph, add the legend
        if scope == "sentence":
            # Create the legend
            legend_labels = [f"{x}ms" for x in window_sizes]
            legend_patches = [Patch(color=bar_colors[i]) for i in range(len(legend_labels))]
            axs[ax_index].legend(legend_patches, legend_labels, loc="upper right")
        # Tweak axis values
        ax_index += 1
        bar_index = 1
    # Save graph
    plt.savefig(f"{GRAPH_LOC}{task}_{measure}_inference_window.jpg")
    plt.close()
for task, measure in zip(["imdb", "emotion", "emotion"], ["accuracy", "accuracy", "mrr"]):
    accuracy_graphs(task, measure)


# Graph 03: //